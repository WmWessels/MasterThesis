{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_tuple(x):\n",
    "    try:\n",
    "        return eval(x)[0]\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gama import GamaClassifier\n",
    "from gama.genetic_programming.components import Individual\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "clf = GamaClassifier(max_total_time=3, store = 'nothing')\n",
    "\n",
    "def convert_str_to_pipeline(pipeline_str: str):\n",
    "    \n",
    "    individual = Individual.from_string(\n",
    "        pipeline_str,\n",
    "        clf._pset,\n",
    "        clf._operator_set._compile\n",
    "    )\n",
    "    pipeline = individual.pipeline\n",
    "    pipeline.steps.insert(0, ('imputation', SimpleImputer(strategy='median')))\n",
    "    pipeline_as_str = f\"{pipeline}\".replace(\" \", \"\").replace(\"\\n\", \"\")\n",
    "\n",
    "    return pipeline_as_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_str_to_sklearn_format(pipeline_str: str):\n",
    "    if pipeline_str.startswith(\"Pipeline\"):\n",
    "        return pipeline_str\n",
    "    else:\n",
    "        return convert_str_to_pipeline(pipeline_str)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "log_path = Path(parent_dir + \"/src/logs/binary\")\n",
    "candidates = set()\n",
    "\n",
    "for folder in log_path.iterdir():\n",
    "\n",
    "    #get the digits from the folder name at the end\n",
    "    dataset_id = str(folder).split(\"_\")[-1]\n",
    "    current_log = pd.read_csv(f\"{folder}/evaluations.log\", delimiter = ';')\n",
    "    current_log[\"pipeline\"] = current_log[\"pipeline\"].apply(lambda x: pipeline_str_to_sklearn_format(x))\n",
    "    current_log.drop_duplicates(subset = \"pipeline\", inplace = True)\n",
    "    current_log[\"score\"] = current_log[\"score\"].apply(lambda x: format_tuple(x)).astype(float)\n",
    "    top_ten = current_log.nlargest(10, \"score\", keep = \"first\")[\"pipeline\"].to_list()\n",
    "    counter = 0\n",
    "    for item in top_ten:\n",
    "        if item not in candidates:\n",
    "            candidates.add(item)\n",
    "            counter += 1\n",
    "        if counter == 5:\n",
    "            break\n",
    "        if item == top_ten[-1]:\n",
    "            print(f\"Could not find 5 unique pipelines for dataset {dataset_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masterthesisenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
