{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import openml\n",
    "import pandas as pd\n",
    "import time\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 39 dataset used for the automl study\n",
    "automlbench_dids = [3, 12, 31, 54, 1067, 1111, 1169, 1596, 1590, 1486, \n",
    "                    1461, 1464, 1468, 1489, 4135, 23517, 40981, 23512, 40668, 41168, \n",
    "                    41166, 41165, 40685, 41159, 41161, 41150, 41138, 41142, 41143, 41146,\n",
    "                    41147, 41163, 41164, 41167, 41169, 40975, 40984, 40996, 41027]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_datasets = openml.datasets.list_datasets()\n",
    "to_consider = openml.datasets.list_datasets()\n",
    "TOTAL = len(all_datasets)\n",
    "\n",
    "to_remove = set()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'did': 3,\n",
       " 'name': 'kr-vs-kp',\n",
       " 'version': 1,\n",
       " 'uploader': '1',\n",
       " 'status': 'active',\n",
       " 'format': 'ARFF',\n",
       " 'MajorityClassSize': 1669.0,\n",
       " 'MaxNominalAttDistinctValues': 3.0,\n",
       " 'MinorityClassSize': 1527.0,\n",
       " 'NumberOfClasses': 2.0,\n",
       " 'NumberOfFeatures': 37.0,\n",
       " 'NumberOfInstances': 3196.0,\n",
       " 'NumberOfInstancesWithMissingValues': 0.0,\n",
       " 'NumberOfMissingValues': 0.0,\n",
       " 'NumberOfNumericFeatures': 0.0,\n",
       " 'NumberOfSymbolicFeatures': 37.0}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_datasets[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_bench_dids = []\n",
    "for did in automlbench_dids:\n",
    "    if all_datasets[did][\"NumberOfClasses\"] == 2:\n",
    "        binary_bench_dids.append(did)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for did in binary_bench_dids:\n",
    "    try:\n",
    "        if all_datasets[did]['NumberOfInstances'] < 250:\n",
    "            to_remove.add(did)\n",
    "        elif all_datasets[did]['NumberOfInstances'] >= 500_000:\n",
    "            to_remove.add(did)\n",
    "        elif all_datasets[did][\"NumberOfFeatures\"] > 2_500:\n",
    "            to_remove.add(did)\n",
    "        elif all_datasets[did]['NumberOfFeatures'] < 2:\n",
    "            to_remove.add(did)\n",
    "        elif all_datasets[did]['NumberOfClasses'] < 2:\n",
    "            to_remove.add(did)\n",
    "        elif all_datasets[did]['NumberOfInstances'] * all_datasets[did]['NumberOfFeatures'] > 10_000_000:\n",
    "            to_remove.add(did)\n",
    "    except KeyError:\n",
    "        to_remove.add(did)\n",
    "\n",
    "binary_bench_dids = [did for did in binary_bench_dids if did not in to_remove]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: 5296\n",
      "To: 5257\n"
     ]
    }
   ],
   "source": [
    "# remove datasets from the datasets list which are in the automl bench or close relatives\n",
    "print(\"From:\", len(to_consider))\n",
    "\n",
    "# remove exact duplicates\n",
    "for did in all_datasets:\n",
    "    if did in automlbench_dids:\n",
    "        to_remove.add(did)\n",
    "\n",
    "for did in to_remove:\n",
    "    if did in to_consider:\n",
    "        del to_consider[did]\n",
    "assert len(to_consider) == len(all_datasets) - 39\n",
    "\n",
    "print(\"To:\", len(to_consider)) # 2965"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: 5257\n",
      "To: 1527\n"
     ]
    }
   ],
   "source": [
    "# Remove datasets with too few features, instances or classes\n",
    "print(\"From:\", len(to_consider))\n",
    "\n",
    "for did in all_datasets:\n",
    "    try:\n",
    "        if all_datasets[did]['NumberOfInstances'] < 250:\n",
    "            to_remove.add(did)\n",
    "        elif all_datasets[did]['NumberOfInstances'] >= 500_000:\n",
    "            to_remove.add(did)\n",
    "        elif all_datasets[did][\"NumberOfFeatures\"] > 2_500:\n",
    "            to_remove.add(did)\n",
    "        elif all_datasets[did]['NumberOfFeatures'] < 2:\n",
    "            to_remove.add(did)\n",
    "        elif all_datasets[did]['NumberOfClasses'] < 2:\n",
    "            to_remove.add(did)\n",
    "        elif all_datasets[did]['NumberOfInstances'] * all_datasets[did]['NumberOfFeatures'] > 10_000_000:\n",
    "            to_remove.add(did)\n",
    "    except KeyError:\n",
    "        #print(did, all_datasets[did])\n",
    "        to_remove.add(did)\n",
    "        \n",
    "for did in to_remove:\n",
    "    if did in to_consider:\n",
    "        del to_consider[did]\n",
    "        \n",
    "print(\"To:\", len(to_consider)) # 651"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_datasets_as_frame = pd.DataFrame.from_dict(all_datasets, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: 1527\n",
      "To: 1518\n"
     ]
    }
   ],
   "source": [
    "# Remove all datasets with \"BNG\" in name\n",
    "print(\"From:\", len(to_consider))\n",
    "\n",
    "for did in to_consider:\n",
    "    if to_consider[did]['name'].startswith(\"BNG\"):\n",
    "        to_remove.add(did)\n",
    "        \n",
    "for did in to_remove:\n",
    "    if did in to_consider:\n",
    "        del to_consider[did]\n",
    "        \n",
    "print(\"To:\", len(to_consider)) # 641"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for similar names and manually check overlaps\n",
    "# def return_triplets(name):\n",
    "#     triplets = set()\n",
    "#     name = name.lower()\n",
    "#     for i in range(len(name) - 2):\n",
    "#         triplets.add(name[i: i+3])\n",
    "#     return triplets\n",
    "\n",
    "# manually_look_at = []\n",
    "# for did in to_consider:\n",
    "#     for did2 in automlbench_dids:\n",
    "#         automl_triplets = return_triplets(all_datasets[did2]['name'])\n",
    "#         other_triplets = return_triplets(all_datasets[did]['name'])\n",
    "#         n_hits = sum([trip in other_triplets for trip in automl_triplets])\n",
    "#         ratio = n_hits / len(automl_triplets)\n",
    "#         if n_hits > 2:\n",
    "#             manually_look_at.append([n_hits, ratio, all_datasets[did]['name'], all_datasets[did2]['name'], did, did2])\n",
    "\n",
    "# df = pd.DataFrame(manually_look_at)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: 1518\n",
      "To: 1482\n"
     ]
    }
   ],
   "source": [
    "# This list contains all manually collected dataset ids as in \n",
    "# https://docs.google.com/spreadsheets/d/1XH1mQFq7-1fs28F-CQJo6i6Wg7IlpDS0aDTAJBoaD7k/edit#gid=0\n",
    "print(\"From:\", len(to_consider))\n",
    "for did in [14, 16, 18, 20, 22, 36, 150, 179, 180, 958, 962, 971, 978, 994, 995, 1020, 1022, 1112, 1113, 1114, \n",
    "            1119, 1242, 1558, 40979, 40997, 40998, 40999, 41000, 41001, 41002, 41003, 41004, 41005, \n",
    "            41006, 41007, 43900, 43947, 44096, 44097, 44098]:\n",
    "    to_remove.add(did)\n",
    " \n",
    "for did in to_remove:\n",
    "    if did in to_consider:\n",
    "        del to_consider[did]\n",
    "print(\"To:\", len(to_consider)) # 603"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for similar metafeatures and manually check overlaps\n",
    "# metafeature_names = [\n",
    "#     'MajorityClassSize', 'MaxNominalAttDistinctValues', 'MinorityClassSize', 'NumberOfClasses',\n",
    "#     'NumberOfFeatures', 'NumberOfInstances', 'NumberOfInstancesWithMissingValues', 'NumberOfMissingValues',\n",
    "#     'NumberOfNumericFeatures', 'NumberOfSymbolicFeatures',\n",
    "# ]\n",
    "\n",
    "# simple_metafeatures_to_consider = pd.DataFrame(\n",
    "#     {k: v for k, v in all_datasets.items() if k in to_consider}\n",
    "# ).transpose()[metafeature_names]\n",
    "# simple_metafeatures_automl = pd.DataFrame(\n",
    "#     {k: v for k, v in all_datasets.items() if k in automlbench_dids}\n",
    "# ).transpose()[metafeature_names]\n",
    "\n",
    "# # Checking the hamming distance of the datasets\n",
    "# manually_look_at = []\n",
    "# for did1, mf1 in simple_metafeatures_to_consider.iterrows():\n",
    "#     for did2, mf2 in simple_metafeatures_automl.iterrows():\n",
    "#         n_hits = np.sum(mf1 == mf2)\n",
    "#         ratio = n_hits / len(mf1)\n",
    "#         n_hits = np.sum(\n",
    "#             mf1[['NumberOfFeatures', 'NumberOfInstances']] == mf2[['NumberOfFeatures', 'NumberOfInstances']]\n",
    "#         )\n",
    "#         if ratio > 0.5 or n_hits == 2:\n",
    "#             entry = [ratio, n_hits, all_datasets[did1]['name'], all_datasets[did2]['name'], did1, did2]\n",
    "#             mfs = np.array([[mf1[n], mf2[n]] for n in metafeature_names]).flatten()\n",
    "#             entry.extend(mfs)\n",
    "#             manually_look_at.append(entry)\n",
    "\n",
    "# header = [\"ratio\", \"n_hits\", \"name\", \"automl name\", \"did\", \"automl did\"] \n",
    "# mfs = list(np.array([[m, m] for m in metafeature_names]).flatten())\n",
    "# df = pd.DataFrame(manually_look_at, columns = header + mfs)\n",
    "# with open(\"ManualMetafeatures.csv\", \"w\") as fh:\n",
    "#    fh.write(df.to_csv())            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: 1482\n",
      "To: 1480\n"
     ]
    }
   ],
   "source": [
    "# This list contains all manually collected dataset ids as in \n",
    "# https://docs.google.com/spreadsheets/d/1SWEBsFTykdUMq-wBcx9NHchhdolB632EJYaAmQwwQtM/edit#gid=0\n",
    "print(\"From:\", len(to_consider))\n",
    "for did in [44153, 44234]:\n",
    "    to_remove.add(did)\n",
    " \n",
    "for did in to_remove:\n",
    "    if did in to_consider:\n",
    "        del to_consider[did]\n",
    "print(\"To:\", len(to_consider)) # 599\n",
    "# check whether we can work usefully with creditcard (1597)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['name', 'NumberOfClasses', 'NumberOfFeatures', 'NumberOfInstances', ]\n",
    "\n",
    "to_consider_stats = pd.DataFrame(\n",
    "    {k: v for k, v in all_datasets.items() if k in to_consider}\n",
    ").transpose()[columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: 1480\n",
      "0.04sec: 25/1480\n",
      "0.07sec: 50/1480\n",
      "0.11sec: 75/1480\n",
      "0.14sec: 100/1480\n",
      "0.16sec: 125/1480\n",
      "0.19sec: 150/1480\n",
      "0.23sec: 175/1480\n",
      "0.26sec: 200/1480\n",
      "0.29sec: 225/1480\n",
      "0.31sec: 250/1480\n",
      "0.35sec: 275/1480\n",
      "0.37sec: 300/1480\n",
      "0.40sec: 325/1480\n",
      "0.43sec: 350/1480\n",
      "0.46sec: 375/1480\n",
      "0.50sec: 400/1480\n",
      "0.54sec: 425/1480\n",
      "0.57sec: 450/1480\n",
      "0.61sec: 475/1480\n",
      "0.64sec: 500/1480\n",
      "0.66sec: 525/1480\n",
      "0.69sec: 550/1480\n",
      "0.71sec: 575/1480\n",
      "0.74sec: 600/1480\n",
      "0.76sec: 625/1480\n",
      "0.79sec: 650/1480\n",
      "0.82sec: 675/1480\n",
      "0.87sec: 700/1480\n",
      "0.90sec: 725/1480\n",
      "0.93sec: 750/1480\n",
      "0.96sec: 775/1480\n",
      "0.98sec: 800/1480\n",
      "1.01sec: 825/1480\n",
      "1.03sec: 850/1480\n",
      "1.06sec: 875/1480\n",
      "1.08sec: 900/1480\n",
      "1.11sec: 925/1480\n",
      "1.13sec: 950/1480\n",
      "1.15sec: 975/1480\n",
      "1.18sec: 1000/1480\n",
      "1.20sec: 1025/1480\n",
      "1.25sec: 1050/1480\n",
      "1.27sec: 1075/1480\n",
      "1.30sec: 1100/1480\n",
      "2.10sec: 1125/1480\n",
      "2.12sec: 1150/1480\n",
      "2.15sec: 1175/1480\n",
      "2.17sec: 1200/1480\n",
      "2.20sec: 1225/1480\n",
      "2.23sec: 1250/1480\n",
      "2.26sec: 1275/1480\n",
      "2.29sec: 1300/1480\n",
      "2.32sec: 1325/1480\n",
      "2.46sec: 1350/1480\n",
      "2.49sec: 1375/1480\n",
      "13.62sec: 1400/1480\n",
      "24.75sec: 1425/1480\n",
      "37.18sec: 1450/1480\n",
      "51.86sec: 1475/1480\n",
      "To: 1227\n"
     ]
    }
   ],
   "source": [
    "# remove sparse datasets\n",
    "print(\"From:\", len(to_consider))\n",
    "start = time.time()\n",
    "for i, did in enumerate(to_consider):\n",
    "    #print(did)\n",
    "    if (i+1) % 25 == 0:\n",
    "        print(\"%4.2fsec: %d/%d\" % (time.time() - start, i+1, len(to_consider)))\n",
    "    d = openml.datasets.get_dataset(int(did), download_data=False)\n",
    "    #print(\n",
    "    #    d.format.lower(), \n",
    "    #    'sparse' in d.format.lower(), \n",
    "    #    d.description and 'CLASSINDEX: none specific' in d.description\n",
    "    #)\n",
    "    for f in d.features.values():\n",
    "        if f.data_type == 'string':\n",
    "            to_remove.add(did)\n",
    "\n",
    "for did in to_remove:\n",
    "    if did in to_consider:\n",
    "        del to_consider[did]\n",
    "print(\"To:\", len(to_consider)) # 599"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove identical/similar datasets (to reduce the load computing the meta-data)\n",
    "# check for similar names and manually check overlaps\n",
    "# def return_triplets(name):\n",
    "#     triplets = set()\n",
    "#     name = name.lower()\n",
    "#     for i in range(len(name) - 2):\n",
    "#         triplets.add(name[i: i+3])\n",
    "#     return triplets\n",
    "\n",
    "# manually_look_at = []\n",
    "# for i, did in enumerate(to_consider):\n",
    "#     for j, did2 in enumerate(to_consider):\n",
    "#         if j <= i:\n",
    "#             continue\n",
    "#         if len(all_datasets[did2]['name']) < 3:\n",
    "#             continue\n",
    "#         other2_triplets = return_triplets(all_datasets[did2]['name'])\n",
    "#         other_triplets = return_triplets(all_datasets[did]['name'])\n",
    "#         n_hits = sum([trip in other_triplets for trip in other2_triplets])\n",
    "#         ratio = n_hits / len(other2_triplets)\n",
    "#         if n_hits > 2:\n",
    "#             manually_look_at.append([n_hits, ratio, all_datasets[did]['name'], all_datasets[did2]['name'], did, did2])\n",
    "\n",
    "# df = pd.DataFrame(manually_look_at)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: 1227\n",
      "To: 1174\n"
     ]
    }
   ],
   "source": [
    "print(\"From:\", len(to_consider))\n",
    "for did in [989, 977, 1222, 997, 1568, 980, 1021, 1019, 1023,\n",
    "            953, 1000, 40474, 40475, 40476, 40477, 40478,\n",
    "            40479, 979, 720, 1557, 990, 41966, 1016, 954,\n",
    "            40597, 976, 1004, 966, 970, 1014, 741, 774, 795,\n",
    "            827, 931, 843, 853, 959, 987, 1037, 1038, 1040,\n",
    "            1560, 1467, 1476, 1566, 1492, 1493, 1525, 1526,\n",
    "            40687, 40926, 41945, 41946, 42140, 42141, 42192]:\n",
    "    to_remove.add(did)\n",
    " \n",
    "for did in to_remove:\n",
    "    if did in to_consider:\n",
    "        del to_consider[did]\n",
    "print(\"To:\", len(to_consider)) # 503"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[715, 718, 723, 730, 732, 740, 742, 743, 744, 746, 749, 751, 763, 766, 769, 773, 776, 779, 792, 793, 794, 797, 799, 805, 806, 813, 824, 830, 832, 834, 837, 838, 845, 849, 855, 863, 866, 869, 870, 873, 877, 879, 884, 888, 896, 903, 904, 910, 911, 912, 913, 917, 918, 920, 926, 933, 935, 936, 937, 943]\n",
      "[1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1543, 1544, 1545, 1546]\n",
      "[1547, 1548, 1549, 1551, 1552, 1553, 1554, 1555]\n",
      "To: 1110\n"
     ]
    }
   ],
   "source": [
    "# Subsample from 'topics', where there are dozens of super-similar\n",
    "# datasots from one source\n",
    "dataset_names = {did: value['name'] for did, value in all_datasets.items()\n",
    "                 if did in to_consider}\n",
    "\n",
    "rng = np.random.RandomState(1)\n",
    "# Friedman datasets\n",
    "friedman_datasets = [\n",
    "    did for did, name in dataset_names.items() if name.startswith('fri_c')\n",
    "]\n",
    "print(friedman_datasets)\n",
    "\n",
    "# volcanoes datasets\n",
    "volcanoes_datasets = [\n",
    "    did for did, name in dataset_names.items() \n",
    "    if name.startswith('volcanoes-')\n",
    "]\n",
    "print(volcanoes_datasets)\n",
    "# AutoUniv\n",
    "auto_univ_datasets = [\n",
    "    did for did, name in dataset_names.items() \n",
    "    if name.startswith('autoUniv-')\n",
    "]\n",
    "print(auto_univ_datasets)\n",
    "for dataset_ids_to_sample_from, num_keep in (\n",
    "    (friedman_datasets, 10),\n",
    "    # (ova_datasets, 7),\n",
    "    (volcanoes_datasets, 10),\n",
    "    (auto_univ_datasets, 4),\n",
    "):\n",
    "    choices_to_drop = np.random.choice(\n",
    "        dataset_ids_to_sample_from,\n",
    "        replace=False,\n",
    "        size=len(dataset_ids_to_sample_from) - num_keep)\n",
    "    for choice in choices_to_drop:\n",
    "        if choice in to_consider:\n",
    "            del to_consider[choice]\n",
    "print(\"To:\", len(to_consider)) # 454"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To: 907\n"
     ]
    }
   ],
   "source": [
    "# Delete a few other datasets\n",
    "\n",
    "# Click prediction datasets consist almost exclusively of IDs\n",
    "dataset_names = {did: value['name'] for did, value in all_datasets.items()\n",
    "                 if did in to_consider\n",
    "                 and value['name'].startswith('Click_prediction')}\n",
    "for did in dataset_names:\n",
    "    if did in to_consider:\n",
    "        del to_consider[did]\n",
    "        \n",
    "\n",
    "\n",
    "# Forex datasets are time series dataset with a time stamp\n",
    "# regularly shuffled tasks won't work here\n",
    "dataset_names = {did: value['name'] for did, value in all_datasets.items()\n",
    "                 if did in to_consider\n",
    "                 and value['name'].startswith('FOREX')}\n",
    "for did in dataset_names:\n",
    "    if did in to_consider:\n",
    "        del to_consider[did]\n",
    "print(\"To:\", len(to_consider)) # 253"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: 907\n",
      "To: 886\n"
     ]
    }
   ],
   "source": [
    "print(\"From:\", len(to_consider))\n",
    "to_remove.update([\n",
    "    312,  # multilabel\n",
    "    313,  # hierarchical classification\n",
    "    316,  # multilabel classification\n",
    "    378,  # unclear target\n",
    "    381,  # unclear target\n",
    "    382,  # unclear target\n",
    "    1178,  # multilabel\n",
    "    1179,  # multilabel\n",
    "    1472,  # regression\n",
    "    1477,  # not a regular classification dataset (stream)\n",
    "    40588,  # multilabel\n",
    "    40589,  # multilabel\n",
    "    40590,  # multilabel\n",
    "    40591,  # multilabel\n",
    "    40592,  # multilabel\n",
    "    40593,  # multilabel\n",
    "    40594,  # multilabel\n",
    "    40595,  # multilabel\n",
    "    40596,  # multilabel\n",
    "    40597,  # multilabel\n",
    "    40686,  # multilabel\n",
    "    40687,  # multilabel\n",
    "    40702,  # multilabel\n",
    "    40910,  # stream dataset\n",
    "    41103,  # description says 'CIFAR-10 dataset but with some modifications'\n",
    "    41526,  # is named test_dataset\n",
    "])\n",
    "for did in to_remove:\n",
    "    if did in to_consider:\n",
    "        del to_consider[did]\n",
    "        \n",
    "print(\"To:\", len(to_consider)) # 232"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for similar metafeatures and manually check overlaps\n",
    "# metafeature_names = [\n",
    "#     'MajorityClassSize', 'MaxNominalAttDistinctValues', 'MinorityClassSize', 'NumberOfClasses',\n",
    "#     'NumberOfFeatures', 'NumberOfInstances', 'NumberOfInstancesWithMissingValues', 'NumberOfMissingValues',\n",
    "#     'NumberOfNumericFeatures', 'NumberOfSymbolicFeatures',\n",
    "# ]\n",
    "\n",
    "# simple_metafeatures_to_consider = pd.DataFrame(\n",
    "#     {k: v for k, v in all_datasets.items() if k in to_consider}\n",
    "# ).transpose()[metafeature_names]\n",
    "\n",
    "# # Checking the hamming distance of the datasets\n",
    "# manually_look_at = []\n",
    "# for did1, mf1 in simple_metafeatures_to_consider.iterrows():\n",
    "#     for did2, mf2 in simple_metafeatures_to_consider.iterrows():\n",
    "#         if did2 <= did1:\n",
    "#             continue\n",
    "#         n_hits = np.sum(mf1 == mf2)\n",
    "#         ratio = n_hits / len(mf1)\n",
    "#         n_hits = np.sum(\n",
    "#             mf1[['NumberOfFeatures', 'NumberOfInstances']] == mf2[['NumberOfFeatures', 'NumberOfInstances']]\n",
    "#         )\n",
    "#         if ratio > 0.5 or n_hits == 2:\n",
    "#             entry = [ratio, n_hits, all_datasets[did1]['name'], all_datasets[did2]['name'], did1, did2]\n",
    "#             mfs = np.array([[mf1[n], mf2[n]] for n in metafeature_names]).flatten()\n",
    "#             entry.extend(mfs)\n",
    "#             manually_look_at.append(entry)\n",
    "\n",
    "# header = [\"ratio\", \"n_hits\", \"name\", \"automl name\", \"did\", \"automl did\"] \n",
    "# mfs = list(np.array([[m, m] for m in metafeature_names]).flatten())\n",
    "# df = pd.DataFrame(manually_look_at, columns = header + mfs)\n",
    "# #with open(\"/tmp/ManualMetafeatures.csv\", \"w\") as fh:\n",
    "#    fh.write(df.to_csv()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: 886\n",
      "To: 876\n"
     ]
    }
   ],
   "source": [
    "print(\"From:\", len(to_consider))\n",
    "for did in [983, 38, 40707, 40708, 40713, 40690, 454, 41156,\n",
    "            40678, 41964]:\n",
    "    to_remove.add(did)\n",
    " \n",
    "for did in to_remove:\n",
    "    if did in to_consider:\n",
    "        del to_consider[did]\n",
    "print(\"To:\", len(to_consider)) # 222"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To: 851\n"
     ]
    }
   ],
   "source": [
    "dataset_names = {did: value['name'] for did, value in all_datasets.items()\n",
    "                 if did in to_consider}\n",
    "for did in [\n",
    "    914,  # Balloon dataset, has only a single features\n",
    "    993,  # not a classification dataset\n",
    "    1002,  # not a classification dataset\n",
    "    1018,  # not a classification dataset\n",
    "    40497,  # regular thyroid dataset\n",
    "    40517,  # artificial drift detection dataset\n",
    "    40666,  # derived from the musk dataset (1116) we use\n",
    "    41158,  # derived from MNIST\n",
    "    41960,  # appears to not be a classification dataset\n",
    "    42344,  # appears to not be a classification dataset\n",
    "    42931,   # string dataset\n",
    "    183, # Too many gama errors, can't evaluate pipelines\n",
    "    4552, # Too many gama errors, can't evaluate pipelines\n",
    "    44186, # dataset version copy\n",
    "    45019, # dataset version copy\n",
    "    40700, # dataset version copy\n",
    "    43901, # only ids as features\n",
    "    41463, # 1 feature with tweets, earlier filtering failed\n",
    "    4340, # too imbalanced\n",
    "    44533, # tooo many classes, problems with cross validation\n",
    "    45103, # tooo many classes, problems with cross validation\n",
    "    44534, # too imbalanced\n",
    "    45102, # too imbalanced\n",
    "]:\n",
    "    to_remove.add(did)\n",
    "\n",
    "for did in [ # recreated samples from automl benchmark datasets\n",
    "    44593, \n",
    "    44498, \n",
    "    44557, \n",
    "    44618, \n",
    "    44780, \n",
    "    44698, \n",
    "    44729, \n",
    "    44535\n",
    "]:\n",
    "    to_remove.add(did)\n",
    "\n",
    "\n",
    "# Not accessible due to errors while accessing the data from openml\n",
    "for did in [\n",
    "    41949,\n",
    "    43148, \n",
    "    43147, \n",
    "    42716\n",
    "]:\n",
    "    to_remove.add(did)\n",
    "    \n",
    "for did in to_remove:\n",
    "    if did in to_consider:\n",
    "        del to_consider[did]\n",
    "print(\"To:\", len(to_consider))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification datasets with NumberoFClasses == 0 in the metafeatures\n",
    "clf_wrong_metafeatures = {\n",
    "     231,\n",
    "     298,\n",
    "     301,\n",
    "     516,\n",
    "     524,\n",
    "     703,\n",
    "     1028,\n",
    "     1097,\n",
    "     1228,\n",
    "     1430,\n",
    "     1432,\n",
    "     1433,\n",
    "     1571,\n",
    "     1572,\n",
    "     1574,\n",
    "     1575,\n",
    "     1579,\n",
    "     1589,\n",
    "     1591,\n",
    "     1593,\n",
    "     4532,\n",
    "     23395,\n",
    "     41943,\n",
    "     42175,\n",
    "     42176,\n",
    "     42464,\n",
    "     42636,\n",
    "}\n",
    "\n",
    "classes = [\n",
    "    2,\n",
    "     2,\n",
    "     2,\n",
    "     3,\n",
    "     3,\n",
    "     3,\n",
    "     4,\n",
    "     3,\n",
    "     2,\n",
    "     2,\n",
    "     2,\n",
    "     2,\n",
    "     2,\n",
    "     2,\n",
    "     2,\n",
    "     2,\n",
    "     2,\n",
    "     2,\n",
    "     3,\n",
    "     3,\n",
    "     2,\n",
    "     2,\n",
    "     2,\n",
    "     2,\n",
    "     2,\n",
    "     2,\n",
    "     2,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.DataFrame(\n",
    "    {k: v for k, v in all_datasets.items() if k in to_consider}\n",
    ").transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_filtered = final.groupby(['NumberOfClasses', 'NumberOfInstances']).sample(n = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_datasets_as_frame.loc[all_datasets_as_frame[\"did\"].isin(clf_wrong_metafeatures), \"NumberOfClasses\"] = classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set display max rows to 25\n",
    "\n",
    "final_frame = pd.concat([final_filtered, all_datasets_as_frame[all_datasets_as_frame[\"did\"].isin(clf_wrong_metafeatures)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_binary = final_frame[final_frame[\"NumberOfClasses\"] == 2]\n",
    "final_multi = final_frame[final_frame[\"NumberOfClasses\"] > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to overwrite ids\n",
    "\n",
    "# final_multi[\"did\"].to_csv(\"dataset_ids/multiclass_dids.csv\", index = False)\n",
    "# final_binary[\"did\"].to_csv(\"dataset_ids/binary_dids.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('masterthesisenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "fa1c239501b12b72b3754f84661a3db9994fa2a1e538f4c0273138e3d7831ed9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
